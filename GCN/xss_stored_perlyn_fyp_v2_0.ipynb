{"cells":[{"cell_type":"code","execution_count":9,"metadata":{"id":"dQGAVE7gplFA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696823594813,"user_tz":-480,"elapsed":295,"user":{"displayName":"Perlyn","userId":"14254918343632488444"}},"outputId":"ec152a52-0a75-4207-91d6-cbe2aac716b9"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 749 µs (started: 2023-10-09 03:53:14 +00:00)\n"]}],"source":["number_of_layers = 3\n","size_of_layer = 256\n","attack_name = \"xssstored\"\n","batch_size = 1\n","epochs = 50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Nuo1Kumxn2K"},"outputs":[],"source":["# get data from drive\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive')\n","drive_path = \"/content/gdrive/MyDrive/fyp_data/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iVAEPwyWlCfo"},"outputs":[],"source":["%pip install networkx==2.5\n","%pip install  dgl -f https://data.dgl.ai/wheels/repo.html\n","%pip install  dglgo -f https://data.dgl.ai/wheels-test/repo.html\n","!pip install ipython-autotime\n","%load_ext autotime"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14471,"status":"ok","timestamp":1696823566760,"user":{"displayName":"Perlyn","userId":"14254918343632488444"},"user_tz":-480},"id":"CpMpZUBgxhw3","outputId":"ef846e38-c74b-4988-9939-6300aa562be9"},"outputs":[{"output_type":"stream","name":"stderr","text":["DGL backend not selected or invalid.  Assuming PyTorch for now.\n"]},{"output_type":"stream","name":"stdout","text":["Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n","Using cpu.\n","time: 14.2 s (started: 2023-10-09 03:52:32 +00:00)\n"]}],"source":["# import required packages\n","import matplotlib.pyplot as plt\n","import networkx as nx\n","import gzip, pickle\n","import dgl\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import dgl.data\n","from dgl.data import DGLDataset\n","import torch as th\n","import json\n","from collections import defaultdict\n","import numpy as np\n","from numpy import array\n","from numpy import argmax\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","from collections import OrderedDict\n","from dgl.nn.pytorch import GraphConv\n","import os\n","from tqdm import tqdm\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torch.optim as optim\n","from dgl.dataloading import GraphDataLoader\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# set constant seed for consistency across multiple settings\n","torch.manual_seed(42)\n","dgl.seed(42)\n","\n","device_name = torch.device('cpu')\n","print(\"Using {}.\".format(device_name))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3-ytnsPAycaz","outputId":"f77606d9-75ff-484e-93cf-27f01da9a3fb"},"outputs":[{"output_type":"stream","name":"stderr","text":[" 49%|████▉     | 977/2000 [14:47<34:01,  2.00s/it]"]}],"source":["node_types = ['argv', 'block', 'address', 'task', 'process_memory', 'file', 'socket', 'pipe', 'iattr', 'link', 'machine', 'path', 'shm']\n","edge_types = ['wasAssociatedW', 'used', 'wasGeneratedBy', 'wasInformedBy', 'wasDerivedFrom']\n","\n","node_features_count = len(node_types)\n","edge_features_count = len(edge_types)\n","\n","targets = np.array(node_types)\n","nodelabelEnc = LabelEncoder()\n","new_target = nodelabelEnc.fit_transform(targets)\n","nodeencoder = OneHotEncoder(sparse_output=False)\n","nodeencoder.fit(new_target.reshape(-1, 1))\n","nodeencoder = nodeencoder\n","\n","targets = np.array(edge_types)\n","edgelabelEnc = LabelEncoder()\n","new_target = edgelabelEnc.fit_transform(targets)\n","edgeencoder = OneHotEncoder(sparse_output=False)\n","edgeencoder.fit(new_target.reshape(-1, 1))\n","edgeencoder = edgeencoder\n","\n","\n","def one_hot_node(data):\n","  new_target = nodelabelEnc.transform(np.array(data))\n","  return torch.from_numpy(nodeencoder.transform(new_target.reshape(-1, 1)))\n","\n","def one_hot_edge(data):\n","  new_target = edgelabelEnc.transform(np.array(data))\n","  return torch.from_numpy(edgeencoder.transform(new_target.reshape(-1, 1)))\n","\n","\n","class ProvenanceDataset(DGLDataset):\n","    def __init__(self):\n","      super().__init__(name='provenance')\n","\n","    def read_graph(self, file_name):\n","      graph_raw = json.load(open(file_name,\"r\"))\n","\n","      list_of_nodes = defaultdict(set)\n","\n","      node_types = {}\n","      edge_types = []\n","\n","      out_edges = []\n","      in_edges = []\n","\n","      for key, value in graph_raw.items():\n","        node1_type, edge_type, node2_type = key.split(\"-\")\n","        node1_index, node2_index = value\n","        for i in node1_index:\n","          node_types[i] = node1_type\n","          edge_types.append(edge_type)\n","        for i in node2_index:\n","          node_types[i] = node2_type\n","\n","\n","        out_edges = out_edges + node1_index\n","        in_edges = in_edges + node2_index\n","\n","      node_types = OrderedDict(sorted(node_types.items()))\n","      number_of_edges = list(node_types.keys())[-1] + 1\n","\n","      for i in range(number_of_edges):\n","        if i not in node_types:\n","          node_types[i] = 'task'\n","\n","      out_edges = th.tensor(out_edges)\n","      in_edges = th.tensor(in_edges)\n","\n","      g = dgl.graph((out_edges, in_edges))\n","\n","      g.ndata['attr'] = (one_hot_node(list(node_types.values())))\n","      g.edata['attr'] = (one_hot_edge(edge_types))\n","\n","      g = dgl.remove_self_loop(g)\n","      g = dgl.add_self_loop(g)\n","\n","      return g\n","\n","    def process(self):\n","        self.graphs = []\n","        self.labels = []\n","\n","        # attack graph ID\n","        for graph_id in tqdm(range(1, 2001)):\n","          g = self.read_graph(f\"{drive_path}{attack_name}_attack/graph{graph_id}.json\")\n","          self.graphs.append(g)\n","          self.labels.append(1)\n","\n","        # benign graph ID\n","        for graph_id in tqdm(range(1, 2001)):\n","          g = self.read_graph(f\"{drive_path}{attack_name}_benign/graph{graph_id}.json\")\n","          self.graphs.append(g)\n","          self.labels.append(0)\n","\n","        # Convert the label list to tensor for saving.\n","        self.labels = torch.LongTensor(self.labels)\n","\n","    def __getitem__(self, i):\n","        return self.graphs[i], self.labels[i]\n","\n","    def __len__(self):\n","        return len(self.graphs)\n","\n","dataset = ProvenanceDataset()\n","graph, label = dataset[0]\n","print(graph, label, graph.device, label.device)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1696823567923,"user":{"displayName":"Perlyn","userId":"14254918343632488444"},"user_tz":-480},"id":"QumtMEOALm8q"},"outputs":[],"source":["train_set, test_set, validation_set = dgl.data.utils.split_dataset(dataset, [0.8, 0.1, 0.1], shuffle=True, random_state=42)\n","data_loader = GraphDataLoader(train_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n","validation_loader = GraphDataLoader(validation_set, batch_size=1, shuffle=True, pin_memory=True)\n","test_loader = GraphDataLoader(test_set, batch_size=1, shuffle=True, pin_memory=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"aborted","timestamp":1696823567923,"user":{"displayName":"Perlyn","userId":"14254918343632488444"},"user_tz":-480},"id":"q6G8iBb8LvN1"},"outputs":[],"source":["class Classifier(nn.Module):\n","    def __init__(self, in_dim, hidden_dim, n_classes, hidden_layer):\n","        super(Classifier, self).__init__()\n","        self.conv1 = GraphConv(in_dim, hidden_dim)\n","        self.hidden_layer = hidden_layer\n","        self.hidden_dim = hidden_dim\n","        if self.hidden_layer == 2:\n","          self.conv2 = GraphConv(hidden_dim, hidden_dim)\n","        if self.hidden_layer == 3:\n","          self.conv3 = GraphConv(hidden_dim, hidden_dim)\n","        self.classify = nn.Linear(hidden_dim, n_classes)\n","\n","    def forward(self, g):\n","        # Use node degree as the initial node feature. For undirected graphs, the in-degree\n","        # is the same as the out_degree.\n","        h = g.ndata['attr'].float()\n","        # Perform graph convolution and activation function.\n","        h = F.relu(self.conv1(g, h))\n","        if self.hidden_layer == 2:\n","          h = F.relu(self.conv2(g, h))\n","        if self.hidden_layer == 3:\n","          h = F.relu(self.conv3(g, h))\n","        g.ndata['h'] = h\n","        # Calculate graph representation by averaging all the node representations.\n","        hg = dgl.mean_nodes(g, 'h')\n","\n","        return self.classify(hg)\n","\n","    def print_params(self):\n","        print(f\"{self.hidden_layer} hidden layers. {self.hidden_dim} hidden dim.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1696823567924,"user":{"displayName":"Perlyn","userId":"14254918343632488444"},"user_tz":-480},"id":"N2q3npS97V4i"},"outputs":[],"source":["def compute_metrics(preds: torch.Tensor, labels: torch.Tensor, threshold: float = 0.5):\n","  is_multiclass = labels.max().item() > 1\n","  if is_multiclass:\n","      preds = torch.argmax(preds, dim=-1)\n","      probs = preds.tolist()  # Predicted class not raw probs\n","  else:\n","      probs = preds.tolist()\n","      preds = (preds > threshold).float()\n","\n","  return {\n","      'accuracy': accuracy_score(preds, labels),\n","      'precision': precision_score(preds, labels, average='micro' if is_multiclass else 'binary'),\n","      'recall': recall_score(preds, labels, average='micro' if is_multiclass else 'binary'),\n","      'F1 micro': f1_score(preds, labels, average='micro'),\n","      'F1 macro': f1_score(preds, labels, average='macro'),\n","      'probs': probs,\n","      'labels': labels.tolist(),\n","  }\n","\n","def eval_model(function_model, dataset_loader, name):\n","  predictions = []\n","  labels = []\n","\n","  with torch.no_grad():\n","      for iter, (bg, label) in enumerate(dataset_loader):\n","          prediction = function_model(bg)\n","          probs_Y = torch.softmax(prediction, 1)\n","          argmax_Y = torch.max(probs_Y, 1)[1].view(-1, 1)\n","          predictions.append(argmax_Y)\n","          labels.append(label)\n","\n","  argmax_Y = torch.cat(predictions, dim=0)\n","  test_Y = torch.cat(labels, dim=0)\n","\n","  print(f\"{name}: {accuracy_score(argmax_Y, test_Y)}\")\n","\n","  return"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1696823567924,"user":{"displayName":"Perlyn","userId":"14254918343632488444"},"user_tz":-480},"id":"DXY_wtenME66"},"outputs":[],"source":["models = []\n","\n","for hidden_layer in [number_of_layers]:\n","  for hidden_dim in [size_of_layer]:\n","    model = Classifier(13, hidden_dim, 2, hidden_layer)\n","    models.append(model)\n","# Create model\n","# model = Classifier(13, 256, 2)\n","# use pretrained model\n","# model.load_state_dict(torch.load(f\"{drive_path}model.pth\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1696823567924,"user":{"displayName":"Perlyn","userId":"14254918343632488444"},"user_tz":-480},"id":"e6l0ngdGcNLt"},"outputs":[],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","def compute_metrics(preds: torch.Tensor, labels: torch.Tensor, threshold: float = 0.5):\n","  is_multiclass = labels.max().item() > 1\n","  if is_multiclass:\n","      preds = torch.argmax(preds, dim=-1)\n","      probs = preds.tolist()  # Predicted class not raw probs\n","  else:\n","      probs = preds.tolist()\n","      preds = (preds > threshold).float()\n","\n","  return {\n","      'accuracy': accuracy_score(preds, labels),\n","      'precision': precision_score(preds, labels, average='micro' if is_multiclass else 'binary'),\n","      'recall': recall_score(preds, labels, average='micro' if is_multiclass else 'binary'),\n","      'F1 micro': f1_score(preds, labels, average='micro'),\n","      'F1 macro': f1_score(preds, labels, average='macro')\n","  }\n","\n","#torch.save(model.state_dict(), \"model.pth\")\n","def print_metrics(model, loader):\n","  predictions = []\n","  labels = []\n","\n","  with torch.no_grad():\n","      model.eval()\n","      for iter, (bg, label) in enumerate(loader):\n","          prediction = model(bg)\n","          probs_Y = torch.softmax(prediction, 1)\n","          argmax_Y = torch.max(probs_Y, 1)[1].view(-1, 1)\n","          predictions.append(argmax_Y)\n","          labels.append(label)\n","      model.train()\n","\n","  argmax_Y = torch.cat(predictions, dim=0)\n","  test_Y = torch.cat(labels, dim=0)\n","\n","  metrics = compute_metrics(argmax_Y, test_Y)\n","  for metric, value in metrics.items():\n","    print(f\"{metric}: {value}\")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":263},"id":"hd1bJ_gWMQsk","outputId":"c5e09d1f-9879-4d9f-9fc4-cb84c90a2ab2","executionInfo":{"status":"error","timestamp":1696823569088,"user_tz":-480,"elapsed":5,"user":{"displayName":"Perlyn","userId":"14254918343632488444"}}},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-8c24e67635bb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mloss_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"]},{"output_type":"stream","name":"stdout","text":["time: 89.6 ms (started: 2023-10-09 03:52:48 +00:00)\n"]}],"source":["for model in models:\n","  model.print_params()\n","  loss_func = nn.CrossEntropyLoss()\n","  optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","  # prepares for training\n","  model.train()\n","  epoch_losses = []\n","  best_validation_loss = 100000000000\n","  epochs_without_gain = 0\n","  end_training = False\n","\n","  for epoch in tqdm(range(epochs)):\n","      epoch_loss = 0\n","      for i in enumerate(data_loader):\n","          iter, (bg, label) = i\n","          prediction = model(bg)\n","          loss = loss_func(prediction, label)\n","          optimizer.zero_grad()\n","          loss.backward()\n","          optimizer.step()\n","          epoch_loss += loss.detach().item()\n","\n","      model.eval()\n","\n","      epoch_loss /= (iter + 1)\n","\n","      validation_loss = 0\n","      for iter, (bg, label) in enumerate(validation_loader):\n","          prediction = model(bg)\n","          validation_loss += loss_func(prediction, label).detach().item()\n","\n","      validation_loss /= (iter + 1)\n","\n","      if validation_loss < best_validation_loss and epoch >= 30:\n","        epochs_without_gain = 0\n","        best_validation_loss = validation_loss\n","        eval_model(model, data_loader, \"train\")\n","        eval_model(model, validation_loader, \"validation\")\n","        eval_model(model, test_loader, \"test\")\n","        torch.save(model.state_dict(), f\"{drive_path}{attack_name}_model{model.hidden_dim}_{model.hidden_layer}.pth\")\n","        print_metrics(model, test_loader)\n","      #elif epoch >= 30:\n","      #  epochs_without_gain += 1\n","      #  if epochs_without_gain > 5:\n","      #    end_training = True\n","\n","      model.train()\n","\n","      print('Epoch {}, loss {:.4f}'.format(epoch, epoch_loss))\n","      epoch_losses.append(epoch_loss)\n","\n","      if end_training:\n","        break"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"4upJKr7GpAlq","outputId":"a65b3f8b-a144-4f8d-b481-cf52ea8631fb","executionInfo":{"status":"error","timestamp":1696823574100,"user_tz":-480,"elapsed":316,"user":{"displayName":"Perlyn","userId":"14254918343632488444"}}},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-bdd559f8350c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{drive_path}{attack_name}_model{model.hidden_dim}_{model.hidden_layer}.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"]},{"output_type":"stream","name":"stdout","text":["time: 27.9 ms (started: 2023-10-09 03:52:53 +00:00)\n"]}],"source":["for model in models:\n","  torch.save(model.state_dict(), f\"{drive_path}{attack_name}_model{model.hidden_dim}_{model.hidden_layer}.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"LMSM4Y3m0dOX","outputId":"1e155eb8-8e6c-4e78-930f-11a5fc7491b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 22.1 ms (started: 2023-10-08 20:15:14 +00:00)\n"]}],"source":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1E3XtbyCEftFCG1U9b7F95vWlNXQyWq9t","timestamp":1696823372579},{"file_id":"1TsxhH-ybFlHVPpqL-58na_fQCvgAfEbH","timestamp":1696690710892}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}